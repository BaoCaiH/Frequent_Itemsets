{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#!/usr/bin/env python<br># coding: utf-8\n",
    "\n",
    "Author: Bao Cai\n",
    "\n",
    "Course: Machine Learning for Descriptive Problems\n",
    "\n",
    "Topic: Frequent Itemsets\n",
    "\n",
    "Start Date: 2020-02-27\n",
    "\n",
    "Last Save: 2020-02-27"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Download the groceries.csv file from itslearning (also the file is in the folder homework inside the zip of this lecture)\n",
    "\n",
    "2. Find the frequent pair of items (2-tuples) using the naÃ¯ve, A-priori and PCY algorithms. For each of these compare the time of execution and results for supports s=10, 50, 100. Comment your results.\n",
    "\n",
    "3. For the PCY algorithm, create up to 5 compact hash tables. What is  the difference in results and time of execution for 1,2,3,4 and 5 tables? Comment your results.\n",
    "\n",
    "4. Find the final list of k-frequent items (k-tuples) for k=3,4 and 5. Experiment a bit and describe the best value for the support in each case. *Warning*: You can use any of the three algorithms, but be careful, because the algorithm can take too long if you don't chose it properly.\n",
    "\n",
    "5. Using one of the results of the previous item, for one k (k=3,4 or 5) find the possible clusters using the 1-NN criteria. Comment your results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import itertools\n",
    "from time import time\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global variables\n",
    "path_data = 'Data/groceries.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "\n",
    "def read_baskets(file, k=2, verbose=True):\n",
    "    \"\"\"\n",
    "    Read a basket file, for each line is a basket.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    \n",
    "    file: str\n",
    "        Path to file.\n",
    "\n",
    "    k: int\n",
    "        Number of max items in a basket.\n",
    "    \n",
    "    verbose: boolean\n",
    "        Choose to report on progress or not.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "\n",
    "    basket_of_k: list\n",
    "        List of baskets of size k.\n",
    "    \"\"\"\n",
    "    with open(file) as f:\n",
    "        baskets = f.readlines()\n",
    "\n",
    "    basket_of_k = []\n",
    "    n = 0\n",
    "    for basket in baskets:\n",
    "        items = basket.replace('\\n', '').split(',')\n",
    "        for itemset in itertools.combinations(items, k):\n",
    "            basket_of_k.append(frozenset(itemset))\n",
    "        if verbose:\n",
    "            n += 1\n",
    "            if n % 1000 == 0:\n",
    "                print(n, 'baskets processed')\n",
    "    return basket_of_k\n",
    "\n",
    "def naive_frequency(baskets):\n",
    "    \"\"\"\n",
    "    Return a dict of frequencies for each basket in given list.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    \n",
    "    baskets: list\n",
    "        List of baskets.\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "\n",
    "    basket_frequency: dict\n",
    "        A frequency corresponds to each basket.\n",
    "    \"\"\"\n",
    "    \n",
    "    basket_frequency = {}\n",
    "    for basket in baskets:\n",
    "        if basket not in basket_frequency:\n",
    "            basket_frequency[basket] = 0\n",
    "        basket_frequency[basket] += 1\n",
    "    return basket_frequency\n",
    "\n",
    "def frequency_threshold(basket_frequency, s=100):\n",
    "    \"\"\"\n",
    "    Return a dict of set frequencies exceed support threshold.\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    \n",
    "    basket_frequency: list\n",
    "        A frequency corresponds to each basket.\n",
    "    \n",
    "    s: int\n",
    "        Support threshold\n",
    "    \n",
    "    Returns:\n",
    "    -------\n",
    "\n",
    "    exceed_frequency: dict\n",
    "        A dict of set frequencies exceed support threshold.\n",
    "    \"\"\"\n",
    "    \n",
    "    exceed_frequency = {}\n",
    "    k = len(list(basket_frequency.keys())[0])\n",
    "    for key, value in basket_frequency.items():\n",
    "        if value >= s:\n",
    "            exceed_frequency[key] = value\n",
    "    print('{} itemsets of size {} with frequency exceed {}'.format(\n",
    "        len(exceed_frequency), k, s\n",
    "    ))\n",
    "    return exceed_frequency\n",
    "\n",
    "def a_piori_preset(\n",
    "    k,\n",
    "    s=100,\n",
    "    larger_set=None,\n",
    "    smaller_set=None\n",
    "):\n",
    "    \n",
    "    basket_size = len(list(larger_set.keys())[0]) +\\\n",
    "                  len(list(smaller_set.keys())[0])\n",
    "    if basket_size != k:\n",
    "        print(\n",
    "            'The given sets cannot be combined',\n",
    "            'to produce a set of', k\n",
    "        )\n",
    "        return None\n",
    "    frequent_preset = set([\n",
    "        a.union(b)\n",
    "        for a in larger_set.keys()\n",
    "        for b in smaller_set.keys()\n",
    "    ])\n",
    "    return frequent_preset\n",
    "\n",
    "def a_piori_filter(\n",
    "    file,\n",
    "    k,\n",
    "    s=100,\n",
    "    frequent_preset=None,\n",
    "    read_baskets=read_baskets,\n",
    "    naive_frequency=naive_frequency,\n",
    "    frequency_threshold=frequency_threshold\n",
    "):\n",
    "    if k == 1:\n",
    "        return frequency_threshold(\n",
    "            naive_frequency(\n",
    "                read_baskets(file, k, False)\n",
    "            ),\n",
    "            s\n",
    "        )\n",
    "    filtered_set = {}\n",
    "    for basket in read_baskets(file, k, False):\n",
    "        if basket not in frequent_preset:\n",
    "            continue\n",
    "        if basket not in filtered_set:\n",
    "            filtered_set[basket] = 0\n",
    "        filtered_set[basket] += 1\n",
    "        \n",
    "    return frequency_threshold(filtered_set, s)\n",
    "\n",
    "def PCY_hash(\n",
    "    file,\n",
    "    k,\n",
    "    n_hash=2,\n",
    "    s=100,\n",
    "    read_baskets=read_baskets\n",
    "):\n",
    "    \n",
    "    hash_tables = []\n",
    "    for i in n_hash:\n",
    "        max_hash = 5*1000000 + i*1024\n",
    "        hash_table.append((np.zeros((max_hash,), dtype=int), max_hash))\n",
    "    \n",
    "    for key in read_baskets(file, k, False):\n",
    "        for hash_table, max_hash in hash_tables:\n",
    "            hash_table[hash(key)%max_hash] += 1\n",
    "    for i in range(len(hash_tables)):\n",
    "        hash_tables[i][0] = set(np.where(hash_tables[i][0] >= s)[0])\n",
    "    return hash_tables\n",
    "\n",
    "def PCY_filter(\n",
    "    file,\n",
    "    k,\n",
    "    s=100,\n",
    "    hash_tables=None,\n",
    "    frequent_preset=None,\n",
    "    read_baskets=read_baskets,\n",
    "    frequency_threshold=frequency_threshold\n",
    "):\n",
    "    filtered_set = {}\n",
    "    for basket in read_baskets(file, k, False):\n",
    "        if basket not in frequent_preset:\n",
    "            continue\n",
    "        accept = True\n",
    "        for hash_table, max_hash in hash_tables:\n",
    "            hashed = hash(basket)%max_hash\n",
    "            if hashed not in hash_table:\n",
    "                accept = False\n",
    "                break\n",
    "        if not accept:\n",
    "            continue\n",
    "        if basket not in filtered_set:\n",
    "            filtered_set[basket] = 0\n",
    "        filtered_set[basket] += 1\n",
    "    return frequency_threshold(filtered_set, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/groceries.csv') as f:\n",
    "    baskets = f.readlines()\n",
    "\n",
    "baskets = [\n",
    "    frozenset(\n",
    "        basket.replace('\\n', '').split(',')\n",
    "    ) for basket in baskets\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 baskets processed\n",
      "2000 baskets processed\n",
      "3000 baskets processed\n",
      "4000 baskets processed\n",
      "5000 baskets processed\n",
      "6000 baskets processed\n",
      "7000 baskets processed\n",
      "8000 baskets processed\n",
      "9000 baskets processed\n"
     ]
    }
   ],
   "source": [
    "baskets = read_baskets(path_data, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 itemsets of size 2 with frequency exceed 100\n",
      "CPU times: user 85 ms, sys: 2.59 ms, total: 87.6 ms\n",
      "Wall time: 83 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_itemsets = naive_frequency(baskets)\n",
    "naive_100_threshold = frequency_threshold(naive_itemsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605 itemsets of size 2 with frequency exceed 50\n",
      "CPU times: user 74.4 ms, sys: 7.66 ms, total: 82.1 ms\n",
      "Wall time: 77.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_itemsets = naive_frequency(baskets)\n",
    "naive_50_threshold = frequency_threshold(naive_itemsets, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1674 itemsets of size 2 with frequency exceed 20\n",
      "CPU times: user 78.6 ms, sys: 2.89 ms, total: 81.5 ms\n",
      "Wall time: 78.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_itemsets = naive_frequency(baskets)\n",
    "naive_20_threshold = frequency_threshold(naive_itemsets, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2981 itemsets of size 2 with frequency exceed 10\n",
      "CPU times: user 79.3 ms, sys: 1.78 ms, total: 81.1 ms\n",
      "Wall time: 78.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_itemsets = naive_frequency(baskets)\n",
    "naive_10_threshold = frequency_threshold(naive_itemsets, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 itemsets of size 3 with frequency exceed 100\n",
      "CPU times: user 1.07 s, sys: 75.8 ms, total: 1.15 s\n",
      "Wall time: 1.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_k3_itemsets = naive_frequency(read_baskets(path_data, 3, False))\n",
    "naive_k3_100_threshold = frequency_threshold(naive_k3_itemsets, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991 itemsets of size 3 with frequency exceed 20\n",
      "CPU times: user 1.48 s, sys: 34.7 ms, total: 1.52 s\n",
      "Wall time: 1.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_k3_itemsets = naive_frequency(read_baskets(path_data, 3, False))\n",
    "naive_k3_20_threshold = frequency_threshold(naive_k3_itemsets, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 itemsets of size 4 with frequency exceed 20\n",
      "CPU times: user 3.36 s, sys: 120 ms, total: 3.48 s\n",
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_k4_itemsets = naive_frequency(read_baskets(path_data, 4, False))\n",
    "naive_k4_20_threshold = frequency_threshold(naive_k4_itemsets, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 itemsets of size 5 with frequency exceed 20\n",
      "CPU times: user 11.8 s, sys: 1.46 s, total: 13.2 s\n",
      "Wall time: 13.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "naive_k5_itemsets = naive_frequency(read_baskets(path_data, 5, False))\n",
    "naive_k5_20_threshold = frequency_threshold(naive_k5_itemsets, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A-Piori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88 itemsets of size 1 with frequency exceed 100\n",
      "120 itemsets of size 1 with frequency exceed 50\n",
      "157 itemsets of size 1 with frequency exceed 10\n"
     ]
    }
   ],
   "source": [
    "apiori_k1_s100 = a_piori_filter(path_data, 1)\n",
    "apiori_k1_s50 = a_piori_filter(path_data, 1, 50)\n",
    "apiori_k1_s10 = a_piori_filter(path_data, 1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiori_k2_s100 = a_piori_preset(\n",
    "    2,\n",
    "    100,\n",
    "    apiori_k1_s100,\n",
    "    apiori_k1_s100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207 itemsets of size 2 with frequency exceed 100\n",
      "CPU times: user 277 ms, sys: 2.97 ms, total: 280 ms\n",
      "Wall time: 278 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "apiori_k2_s100 = a_piori_filter(\n",
    "    path_data,\n",
    "    2,\n",
    "    100,\n",
    "    apiori_k2_s100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiori_k2_s50 = a_piori_preset(\n",
    "    2,\n",
    "    50,\n",
    "    apiori_k1_s50,\n",
    "    apiori_k1_s50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "605 itemsets of size 2 with frequency exceed 50\n",
      "CPU times: user 271 ms, sys: 2.84 ms, total: 274 ms\n",
      "Wall time: 271 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "apiori_k2_s50 = a_piori_filter(\n",
    "    path_data,\n",
    "    2,\n",
    "    50,\n",
    "    apiori_k2_s50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiori_k2_s10 = a_piori_preset(\n",
    "    2,\n",
    "    10,\n",
    "    apiori_k1_s10,\n",
    "    apiori_k1_s10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2981 itemsets of size 2 with frequency exceed 10\n",
      "CPU times: user 340 ms, sys: 1.91 ms, total: 342 ms\n",
      "Wall time: 339 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "apiori_k2_s10 = a_piori_filter(\n",
    "    path_data,\n",
    "    2,\n",
    "    10,\n",
    "    apiori_k2_s10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiori_k3_s100 = a_piori_preset(\n",
    "    3,\n",
    "    100,\n",
    "    apiori_k2_s100,\n",
    "    apiori_k1_s100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31 itemsets of size 3 with frequency exceed 100\n",
      "CPU times: user 2.84 s, sys: 33.4 ms, total: 2.87 s\n",
      "Wall time: 2.85 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "apiori_k3_s100 = a_piori_filter(\n",
    "    path_data,\n",
    "    3,\n",
    "    100,\n",
    "    apiori_k3_s100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 itemsets of size 1 with frequency exceed 20\n",
      "1674 itemsets of size 2 with frequency exceed 20\n"
     ]
    }
   ],
   "source": [
    "apiori_k1_s20 = a_piori_filter(path_data, 1, 20)\n",
    "apiori_k2_s20 = a_piori_preset(\n",
    "    2,\n",
    "    20,\n",
    "    apiori_k1_s20,\n",
    "    apiori_k1_s20\n",
    ")\n",
    "apiori_k2_s20 = a_piori_filter(\n",
    "    path_data,\n",
    "    2,\n",
    "    20,\n",
    "    apiori_k2_s20\n",
    ")\n",
    "\n",
    "apiori_k3_s20 = a_piori_preset(\n",
    "    3,\n",
    "    20,\n",
    "    apiori_k2_s20,\n",
    "    apiori_k1_s20\n",
    ")\n",
    "\n",
    "apiori_k4_s20 = a_piori_preset(\n",
    "    4,\n",
    "    20,\n",
    "    apiori_k2_s20,\n",
    "    apiori_k2_s20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991 itemsets of size 3 with frequency exceed 20\n",
      "CPU times: user 10.5 s, sys: 32.7 s, total: 43.1 s\n",
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "apiori_k3_s20 = a_piori_filter(\n",
    "    path_data,\n",
    "    3,\n",
    "    20,\n",
    "    apiori_k3_s20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "apiori_k5_s20 = a_piori_preset(\n",
    "    5,\n",
    "    20,\n",
    "    apiori_k3_s20,\n",
    "    apiori_k2_s20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 itemsets of size 4 with frequency exceed 20\n",
      "CPU times: user 28.3 s, sys: 1min 43s, total: 2min 11s\n",
      "Wall time: 4min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "apiori_k4_s20 = a_piori_filter(\n",
    "    path_data,\n",
    "    4,\n",
    "    20,\n",
    "    apiori_k4_s20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "apiori_k5_s20 = a_piori_filter(\n",
    "    path_data,\n",
    "    5,\n",
    "    20,\n",
    "    apiori_k5_s20\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basket size 2 and 3 seems large so I checked with Naive method above and it's checked out.\n",
    "\n",
    "Also, I think the more advance algorithm will benefit when the number of items in a single basket is relatively large or equal to the number of unique items. The reason behind that statement is that for this dataset, there's not much 5 items basket (I guess, I didn't open many of them), so naive method can just run through them and count pretty easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
